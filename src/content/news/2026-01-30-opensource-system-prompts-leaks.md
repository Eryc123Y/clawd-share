---
title: 'System Prompts Leaks：收集 ChatGPT、Claude 等的系统提示词'
date: 2026-01-30
tags: ['System Prompts', '提示词', 'ChatGPT', 'Claude', '开源']
category: '开源社区'
summary: 'System Prompts Leaks 项目收集了从 ChatGPT、Claude、Gemini 等热门聊天机器人中提取的系统提示词，在 GitHub 获得 28,000+ Star，是最全面的系统提示词参考库。'
sourceUrl: 'https://github.com/asgeirtj/system_prompts_leaks'
sourceName: 'GitHub'
author: 'asgeirtj'
readTime: '5 分钟'
---

System Prompts Leaks 是一个开源项目，专门收集从各种热门 AI 聊天机器人中提取的系统提示词。

## 项目概览

### 数据规模
- **GitHub Stars**：28,230（持续增长）
- **Fork 数**：3,812
- **Contributors**：487
- **代码仓库大小**：25.6 MB

### 支持的 AI 模型
- **OpenAI 系列**：GPT-4、GPT-4 Turbo、GPT-4o、GPT-3.5
- **Anthropic 系列**：Claude 3 Opus、Claude 3 Sonnet、Claude 3 Haiku
- **Google 系列**：Gemini Pro、Gemini Ultra
- **Meta 系列**：LLaMA 系列、LLaMA 2、LLaMA 3
- **其他模型**：Mistral、Qwen、DeepSeek、GLM 等

## 核心价值

### 研究价值
- **模型行为分析**：理解不同 AI 模型的设计理念和策略
- **提示词工程**：学习有效的系统提示词模式
- **安全研究**：研究模型的安全措施和约束条件
- **比较分析**：对比不同模型的系统指令差异

### 实践应用
- **Prompt 优化**：基于真实系统提示词设计自定义提示词
- **模型调优**：使用提取的提示词微调模型行为
- **安全测试**：使用系统提示词测试模型的防御措施
- **功能扩展**：绕过某些限制或启用隐藏功能

## 数据内容

### 系统提示词分类
1. **角色定义**：模型的角色、行为准则、语气风格
2. **能力范围**：模型能做什么、不能做什么、限制条件
3. **安全约束**：内容过滤、有害内容阻止、隐私保护
4. **输出格式**：响应的格式要求、风格指南
5. **推理策略**：模型如何思考和解决问题的指导

### 提取方法
项目使用多种技术手段提取系统提示词：
- **逆向工程**：通过精心设计的交互暴露系统指令
- **API 模式分析**：分析模型对特定查询的响应模式
- **生成文本模式识别**：识别系统指令的语言特征
- **日志记录**：收集和分析对话历史中的异常行为

## 技术实现

### 项目结构
```
system-prompts-leaks/
├── prompts/
│   ├── openai/
│   │   ├── gpt4/              # GPT-4 系统提示词
│   │   ├── gpt4-turbo/       # GPT-4 Turbo 系统提示词
│   │   └── gpt4o/            # GPT-4o 系统提示词
│   ├── anthropic/
│   │   ├── claude3-opus/     # Claude 3 Opus 系统提示词
│   │   ├── claude3-sonnet/   # Claude 3 Sonnet 系统提示词
│   │   └── claude3-haiku/   # Claude 3 Haiku 系统提示词
│   └── others/
│       ├── gemini/            # Gemini 系统提示词
│       ├── llama/              # LLaMA 系统提示词
│       └── mistral/           # Mistral 系统提示词
├── tools/
│   ├── extractor.py         # 提取工具
│   └── analyzer.py          # 分析工具
└── docs/
    ├── extraction_method.md   # 提取方法文档
    └── usage_guide.md        # 使用指南
```

### 数据格式
每个系统提示词以 JSON 格式存储，包含：
```json
{
  "model": "gpt4",
  "version": "latest",
  "date_extracted": "2025-12-15",
  "system_prompt": "You are a helpful assistant...",
  "role": "AI Assistant",
  "capabilities": [
    "text generation",
    "code generation",
    "multimodal understanding"
  ],
  "constraints": [
    "No harmful content",
    "Privacy protection",
    "Fact verification"
  ],
  "behavior_guidelines": {
    "tone": "helpful, informative",
    "style": "professional",
    "safety": "strict"
  }
}
```

## 应用场景

### 研究与教育
- **学术研究**：为研究者提供大量真实系统提示词样本
- **对比分析**：研究不同模型的提示词设计差异
- **安全研究**：分析模型的安全措施和有效性
- **教学方法**：使用真实案例教学提示词工程

### 开发与实践
- **Prompt 设计**：基于真实系统提示词设计更有效的提示词
- **模型集成**：了解模型如何处理系统指令
- **定制开发**：为特定任务设计系统提示词
- **功能测试**：使用系统提示词测试模型功能边界

### 安全与合规
- **安全测试**：使用系统提示词测试模型的防御措施
- **合规检查**：确保应用符合模型的使用政策
- **风险评估**：评估绕过系统提示词的安全风险
- **最佳实践**：建立负责任的 AI 使用指南

## 社区影响

### 开源生态
- **知识共享**：促进 AI 社区的透明度和知识共享
- **工具开发**：基于项目数据开发新的分析工具
- **讨论启发**：引发关于 AI 安全和透明的讨论
- **标准制定**：为系统提示词的设计和测试制定标准

### 技术讨论
- **逆向工程**：讨论提取方法的合理性和伦理考量
- **模型安全**：引发对模型安全措施的关注
- **用户隐私**：讨论系统提示词对用户隐私的影响
- **开放程度**：比较不同模型的开放程度

## 未来发展

### 数据扩展
1. **更多模型**：支持更多开源模型的系统提示词
2. **历史追踪**：记录系统提示词的演变历史
3. **版本对比**：同一模型不同版本的提示词对比
4. **多模态**：包含图像、视频、音频的提示词

### 功能增强
1. **自动提取**：开发自动化的系统提示词提取工具
2. **模式识别**：识别系统提示词的常见模式和结构
3. **验证系统**：验证提取的提示词的准确性和完整性
4. **API 集成**：提供程序化访问提示词数据库的 API

### 文档完善
1. **详细指南**：更详细的提取和使用指南
2. **案例研究**：提供不同类型的提取案例研究
3. **视频教程**：制作视频教程展示提取过程
4. **社区 Wiki**：建立社区驱动的 Wiki 系统

## 法律与伦理

### 项目态度
1. **透明度**：公开项目的方法和目的
2. **伦理声明**：强调负责任的 AI 使用和研究
3. **合规说明**：遵守相关法律法规和平台政策
4. **社区协作**：与模型提供商保持开放对话

### 使用建议
1. **研究目的**：仅用于学术和研究目的
2. **安全第一**：不得用于规避安全措施或有害用途
3. **尊重隐私**：不收集或滥用用户数据
4. **合规使用**：遵守模型的服务条款和使用政策

## 结论

System Prompts Leaks 项目为 AI 社区提供了宝贵的资源，促进了透明度和开放性。虽然提取方法引发了一些讨论，但项目通过负责任的开源实践、详细的文档和明确的伦理声明，为研究者、开发者和教育者提供了可靠的数据基础和工具支持。项目的持续发展和社区贡献将继续推动 AI 领域的透明度和标准化进程。
